{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Data Cleaning\n",
    "\n",
    "This notebook contains the first stage of the data cleaning process for the project dataset. It focuses on identifying and handling inconsistencies, missing values, and formatting issues to prepare the data for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "\n",
    "We import the necessary libraries for data analysis and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "Load the dataset from a CSV file for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Loading\n",
    "\n",
    "# Define the relative path to the data file\n",
    "data_path = '../data/raw/dataset.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    # Attempt to read with UTF-8 encoding first\n",
    "    df = pd.read_csv(data_path, encoding='utf-8') \n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        # Fallback to Latin-1 encoding if UTF-8 fails\n",
    "        df = pd.read_csv(data_path, encoding='latin1') \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        df = None  # Indicate failure by setting df to None\n",
    "\n",
    "# Check if the dataset loaded correctly\n",
    "if df is not None:\n",
    "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"Error loading dataset. Please verify the file path and encoding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unnecessary Columns\n",
    "\n",
    "Drop columns that are not relevant for the analysis to simplify the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display initial shape and columns of the dataframe\n",
    "print(f\"Initial dataframe shape: {df.shape}\")\n",
    "print(f\"Dataframe columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop (modify as needed)\n",
    "columns_to_drop = [\"col1\", \"col2\", \"col3\", \"col4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from the dataframe\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final dataframe shape and columns after dropping unnecessary columns\n",
    "print(f\"Final dataframe shape after dropping columns: {df.shape}\")\n",
    "print(f\"Dataframe columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Error Correction and Category Unification\n",
    "\n",
    "In this step, we identify and correct encoding errors and unify similar categories across columns to improve data quality and consistency.\n",
    "\n",
    "For each affected column, we replace incorrect or inconsistent values with their corrected or unified forms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Replace encoding errors and unify categories for selected columns\n",
    "corrections = {\n",
    "    'COLUMN_1': {\n",
    "        'IncorrectValue1': 'CorrectValue1',\n",
    "        'IncorrectValue2': 'CorrectValue2',\n",
    "        # ...\n",
    "    },\n",
    "    'COLUMN_2': {\n",
    "        'OldCategoryA': 'UnifiedCategoryA',\n",
    "        'OldCategoryB': 'UnifiedCategoryA',\n",
    "        # ...\n",
    "    },\n",
    "    # Add more columns as needed\n",
    "}\n",
    "\n",
    "for col, mapping in corrections.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Cleaned Data to CSV\n",
    "\n",
    "The cleaned dataset is exported to a CSV file located at ../data/processed/cleaned_data.csv for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    path_or_buf='../data/processed/cleaned_data.csv',\n",
    "    sep=',',\n",
    "    na_rep='',\n",
    "    header=True,\n",
    "    index=False,\n",
    "    encoding='utf-8',\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    lineterminator=os.linesep,\n",
    "    quotechar='\"',\n",
    "    decimal='.',\n",
    "    errors='strict'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
